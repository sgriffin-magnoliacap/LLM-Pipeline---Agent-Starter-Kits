# llm/models.yaml

# Available models and their host/provider
available_models:
  grok-3-mini:
    model_name: grok-3-mini
    provider: xai
    temperature: 0.0
    multimodal: false
  o3-mini:
    provider: openai # only allows temp of 1, optional reasoning_effort: high parameter
    temperature: 1
    reasoning_effort: high
  o4-mini:
    provider: openai # only allows temp of 1, optional reasoning_effort: high parameter
    temperature: 1
    multimodal: true
  gpt-4o:
    provider: openai
    temperature: 0.0
    multimodal: true
  o3:
    provider: openai
    temperature: 0.0
    multimodal: true

# Tasks and their model
default:
  model_name: o3-mini
analyze-text:
  model_name: o3-mini
analyze-webpage:
  model_name: o4-mini
analyze-image-url:
  model_name: o4-mini
analyze-image-base64:
  model_name: gpt-4o
analyze-pdf-base64:
  model_name: gpt-4o

# Max retries for LLM calls
max_retries: 3